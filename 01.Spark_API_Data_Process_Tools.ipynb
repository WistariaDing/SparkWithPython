{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Python Logo](https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/pyspark_logo.jpeg)\n",
    "This notebook is to introduce how to use Spark API to process data in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc=pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) map\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.1.map.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[(1, 1), (2, 4), (3, 9)]\n"
     ]
    }
   ],
   "source": [
    "# parallelize creates an RDD from the passed object\n",
    "x = sc.parallelize([1,2,3])\n",
    "y = x.map(lambda x: (x,x**2))\n",
    "\n",
    "# collect copies RDD elements to a list on the driver\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) flatMap\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.2.flatMap.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 100, 1, 2, 200, 4, 3, 300, 9]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = x.flatMap(lambda x: (x,100*x,x**2))\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3)mapPartitions\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.3.mapPartitions.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 3]]\n",
      "[[1], [5]]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3],2)\n",
    "def f(iterator): yield sum(iterator)\n",
    "y = x.mapPartitions(f)\n",
    "# glom() falttens elements on the same partition\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) mapPartitionsWithIndex\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.4.mapPartitionsWithIndex.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 3]]\n",
      "[[(0, 1)], [(1, 5)]]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3],2)\n",
    "def f(partitionIndex,iterator): yield (partitionIndex, sum(iterator))\n",
    "y = x.mapPartitionsWithIndex(f)\n",
    "print(x.glom().collect())\n",
    "print(y.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) getNumPartitions\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.5.getNumPartitions.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 3]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "y = x.getNumPartitions()\n",
    "print(x.glom().collect())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) filter\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.6.filter.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = x.filter(lambda x:x%2==1) # filter out elements\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) distinct\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.6.filter.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'B']\n",
      "['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(['A','A','B'])\n",
    "y = x.distinct()\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) sample\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.8.sample.PNG\" width=\"300\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0, 1, 2, 3, 4, 5, 6]\n",
      "sample: 0 y = [4, 5]\n",
      "sample: 1 y = [0, 1, 5, 6]\n",
      "sample: 2 y = [2, 4, 6]\n",
      "sample: 3 y = [4, 5, 6]\n",
      "sample: 4 y = [1, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(range(7))\n",
    "ylist = [x.sample(withReplacement=False,fraction=0.5) for i in range(5)]\n",
    "print('x = '+str(x.collect()))\n",
    "for cnt, y in zip(range(len(ylist)),ylist):\n",
    "    print('sample: '+str(cnt)+' y = '+str(y.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (9) takeSample\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.9.takeSample.PNG\" width=\"300\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0, 1, 2, 3, 4, 5, 6]\n",
      "sample: 0 y = [0, 4, 3]\n",
      "sample: 1 y = [4, 5, 2]\n",
      "sample: 2 y = [0, 5, 4]\n",
      "sample: 3 y = [6, 0, 2]\n",
      "sample: 4 y = [2, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(range(7))\n",
    "ylist = [x.takeSample(withReplacement=False,num=3) for i in range(5)]\n",
    "print('x = '+str(x.collect()))\n",
    "for cnt, y in zip(range(len(ylist)),ylist):\n",
    "    print('sample: '+str(cnt)+' y = '+str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10) union\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.10.union.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'B']\n",
      "['D', 'C', 'A']\n",
      "['A', 'A', 'B', 'D', 'C', 'A']\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(['A','A','B'])\n",
    "y = sc.parallelize(['D','C','A'])\n",
    "z = x.union(y)\n",
    "print(x.collect())\n",
    "print(y.collect())\n",
    "print(z.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (11) intersection\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.11.intersection.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'B']\n",
      "['A', 'C', 'D']\n",
      "['A']\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(['A','A','B'])\n",
    "y = sc.parallelize(['A','C','D'])\n",
    "z = x.intersection(y)\n",
    "print(x.collect())\n",
    "print(y.collect())\n",
    "print(z.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (12) sortByKey\n",
    "<img src=\"https://raw.githubusercontent.com/WistariaDing/SparkWithPython/master/Picture/1.12.sortByKey.PNG\" width=\"300\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', 1), ('A', 2), ('C', 3)]\n",
      "[('A', 2), ('B', 1), ('C', 3)]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([('B',1),('A',2),('C',3)])\n",
    "y = x.sortByKey()\n",
    "print(x.collect())\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
